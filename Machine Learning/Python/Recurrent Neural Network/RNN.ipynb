import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
from torch import nn
from torch.autograd import Variable
%matplotlib inline

# Input data to train the network
data_csv = pd.read_csv('data.csv', usecols=[1])
plt.plot(data_csv)

# Preprocess data
data_csv = data_csv.dropna()
dataset = data_csv.values
dataset = dataset.astype('float32')
max_value = np.max(dataset)
min_value = np.min(dataset)
scalar = max_value - min_value
dataset = list(map(lambda x: x / scalar, dataset))

# Create dataset for LSTM - Note the argument look_back
def create_dataset(dataset, look_back=2):
    dataX, dataY = [], []
    for i in range(len(dataset) - look_back):
        a = dataset[i:(i + look_back)]
        dataX.append(a)
        dataY.append(dataset[i + look_back])
    return np.array(dataX), np.array(dataY)
data_X, data_Y = create_dataset(dataset)

# Create train and test sets
train_size = int(len(data_X) * 0.7)
test_size = len(data_X) - train_size
train_X = data_X[:train_size]
train_Y = data_Y[:train_size]
test_X = data_X[train_size:]
test_Y = data_Y[train_size:]

# Reshape data to use with LSTM
train_X = train_X.reshape(-1, 1, 2)
train_Y = train_Y.reshape(-1, 1, 1)
test_X = test_X.reshape(-1, 1, 2)

train_x = torch.from_numpy(train_X)
train_y = torch.from_numpy(train_Y)
test_x = torch.from_numpy(test_X)

# Define the LSTM module
class lstm_reg(nn.Module):
    def __init__(self, input_size, hidden_size, output_size=1, num_layers=2):
        super(lstm_reg, self).__init__()
        
        self.rnn = nn.LSTM(input_size, hidden_size, num_layers)  # LSTM-rnn
        self.reg = nn.Linear(hidden_size, output_size)  # Linear regression
        
    def forward(self, x):
        x, _ = self.rnn(x)  # (seq, batch, hidden)
        s, b, h = x.shape
        x = x.view(s*b, h)
        x = self.reg(x)
        x = x.view(s, b, -1)
        return x

# Configure network
net = lstm_reg(2, 4)
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)

# Train LSTM using the defined criteria and optimizer
epochs = 10
losses = np.zeros(epochs)
for e in range(epochs):
    var_x = Variable(train_x)
    var_y = Variable(train_y)
  
    out = net(var_x)
    loss = criterion(out, var_y)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    # Insert code to plot the loss
    losses[e] += loss.data
plt.plot(losses)

# Get the network ready for evaluation
net = net.eval()

# Pass the test data to the network
data_X = data_X.reshape(-1, 1, 2)
data_X = torch.from_numpy(data_X)
var_data = Variable(data_X)
pred_test = net(var_data)
pred_test = pred_test.view(-1).data.numpy()

# Plot the real and predicted values
plt.plot(pred_test, 'r', label='prediction')
plt.plot(dataset, 'b', label='real')
plt.legend(loc='best')

# 1 hidden layer
net = lstm_reg(2, 4, num_layers=1) 
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)

# Train LSTM using the defined criteria and optimizer
epochs = 10
losses1 = np.zeros(epochs)
for e in range(epochs):
    var_x = Variable(train_x)
    var_y = Variable(train_y)
  
    out = net(var_x)
    loss = criterion(out, var_y)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    # Insert code to plot the loss
    losses1[e] += loss.data

# 2 hidden layers
net = lstm_reg(2, 4, num_layers=2) 
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)

# Train LSTM using the defined criteria and optimizer
epochs = 10
losses2 = np.zeros(epochs)
for e in range(epochs):
    var_x = Variable(train_x)
    var_y = Variable(train_y)
  
    out = net(var_x)
    loss = criterion(out, var_y)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    # Insert code to plot the loss
    losses2[e] += loss.data

# 3 hidden layers
net = lstm_reg(2, 4, num_layers=3) 
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)

# Train LSTM using the defined criteria and optimizer
epochs = 10
losses3 = np.zeros(epochs)
for e in range(epochs):
    var_x = Variable(train_x)
    var_y = Variable(train_y)
  
    out = net(var_x)
    loss = criterion(out, var_y)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    # Insert code to plot the loss
    losses3[e] += loss.data

plt.plot(losses1)
plt.plot(losses2)
plt.plot(losses3)
plt.legend(["1 hidden layer","2 hidden layers","3 hidden layers"])

# Small learning rate
net = lstm_reg(2, 4) 
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(net.parameters(), lr=(1e-2)/10)

# Train LSTM using the defined criteria and optimizer
epochs = 10
losses1 = np.zeros(epochs)
for e in range(epochs):
    var_x = Variable(train_x)
    var_y = Variable(train_y)
  
    out = net(var_x)
    loss = criterion(out, var_y)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    # Insert code to plot the loss
    losses1[e] += loss.data

# Large learning rate
net = lstm_reg(2, 4) 
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(net.parameters(), lr=(1e-2)*10)

# Train LSTM using the defined criteria and optimizer
epochs = 10
losses2 = np.zeros(epochs)
for e in range(epochs):
    var_x = Variable(train_x)
    var_y = Variable(train_y)
  
    out = net(var_x)
    loss = criterion(out, var_y)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    # Insert code to plot the loss
    losses2[e] += loss.data

# Optimum learning rate
net = lstm_reg(2, 4) 
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)

# Train LSTM using the defined criteria and optimizer
epochs = 10
losses3 = np.zeros(epochs)
for e in range(epochs):
    var_x = Variable(train_x)
    var_y = Variable(train_y)
  
    out = net(var_x)
    loss = criterion(out, var_y)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    # Insert code to plot the loss
    losses3[e] += loss.data
plt.plot(losses1)
plt.plot(losses2)
plt.plot(losses3)
plt.legend(["Small learning rate","Large learning rate","Optimum learning rate"])

import time
# Total of 10 epochs
net = lstm_reg(2, 4) 
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)

# Train LSTM using the defined criteria and optimizer
epochs = 10
losses1 = np.zeros(epochs)
start_time = time.time()
for e in range(epochs):
    var_x = Variable(train_x)
    var_y = Variable(train_y)
  
    out = net(var_x)
    loss = criterion(out, var_y)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    # Insert code to plot the loss
    losses1[e] += loss.data
    
# Get the network ready for evaluation
net = net.eval()

# Pass the test data to the network
pred_test = net(var_data)
pred_test = pred_test.view(-1).data.numpy()

# Plot the real and predicted values
plt.plot(dataset, 'b', label='real')
plt.plot(pred_test, 'r', label='prediction')
plt.legend(loc='best')
elapsed_time = time.time() - start_time
print("The elapsed time is: {} s".format(elapsed_time))

import time
# Total of 100 epochs
net = lstm_reg(2, 4) 
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)

# Train LSTM using the defined criteria and optimizer
epochs = 100
losses2 = np.zeros(epochs)
start_time = time.time()
for e in range(epochs):
    var_x = Variable(train_x)
    var_y = Variable(train_y)
  
    out = net(var_x)
    loss = criterion(out, var_y)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    # Insert code to plot the loss
    losses2[e] += loss.data
    
# Get the network ready for evaluation
net = net.eval()

# Pass the test data to the network
pred_test = net(var_data)
pred_test = pred_test.view(-1).data.numpy()

# Plot the real and predicted values
plt.plot(dataset, 'b', label='real')
plt.plot(pred_test, 'r', label='prediction')
plt.legend(loc='best')
elapsed_time = time.time() - start_time
print("The elapsed time is: {} s".format(elapsed_time))

import time
# Total of 1000 epochs
net = lstm_reg(2, 4) 
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)

# Train LSTM using the defined criteria and optimizer
epochs = 1000
losses3 = np.zeros(epochs)
start_time = time.time()
for e in range(epochs):
    var_x = Variable(train_x)
    var_y = Variable(train_y)
  
    out = net(var_x)
    loss = criterion(out, var_y)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    # Insert code to plot the loss
    losses3[e] += loss.data
    
# Get the network ready for evaluation
net = net.eval()

# Pass the test data to the network
pred_test = net(var_data)
pred_test = pred_test.view(-1).data.numpy()

# Plot the real and predicted values
plt.plot(dataset, 'b', label='real')
plt.plot(pred_test, 'r', label='prediction')
plt.legend(loc='best')
elapsed_time = time.time() - start_time
print("The elapsed time is:{} s".format(elapsed_time))


